\documentclass[11pt,letterpaper]{article}

\usepackage{showlabels}
\usepackage{fullpage}
\usepackage{pslatex}
%\usepackage{latexsym}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{url}
%\usepackage[colorinlistoftodos]{todonotes}
\usepackage{rotating}
\usepackage{natbib}
\usepackage{amssymb}

\usepackage{tikz-dependency}
\usepackage{longtable}


\newcommand{\R}[0]{\mathbb{R}}
\newcommand{\E}[0]{\mathbb{E}}
\newcommand{\Ff}[0]{\mathcal{F}}

\usepackage{multirow}

\newcommand{\soft}[1]{}
\newcommand{\nopreview}[1]{}
\newcommand\comment[1]{{\color{red}#1}}
\newcommand\mhahn[1]{{\color{red}(#1)}}

\usepackage{amsthm}

\newcommand{\thetad}[0]{{\theta_d}}
\newcommand{\thetal}[0]{{\theta_{LM}}}

\newcounter{theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{thm}[theorem]{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{question}[theorem]{Question}
\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}


\frenchspacing
%\def\baselinestretch{0.975}

%\emnlpfinalcopy
%\def\emnlppaperid{496}

\title{TODO title}
\author{Michael Hahn, Judith Degen, Richard Futrell}
\date{2019}

\begin{document}

\maketitle

Languages order words

Languages have different word orders

test hypothesis that these grammars represent different solutions to efficient computation.

For several decades, basically everyone has been saying something like this on a theoretical level, from Chomsky (approximately since the 90s?) to Hawkins.

This has been difficult to test for two reasons:

(1) Need a lot of data representing the distribution of underlying hierarchical structures that people communicate,

(2) Need computational model of efficiency in computation.

We use information-theory to for the first time really test (2).
We use information-theoretical lower bounds on the difficulty in language processing.

surprisal as processing effort

memory: how many bits of memory about past input does a listener need to represent.

related to work in physics on the ability of physical systems to represent memory, representing more bits costs more memory.

memory-surprisal tradeoff

conditional MI

theorem

what we did

results

some discussion

this subsumes previous ideas about locality in language


\end{document}


